{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9bf8e6fbd69d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "with open('test.csv', 'r') as csvfile:\n",
    "    lines = csv.reader(csvfile)\n",
    "    for row in lines:\n",
    "        print(', '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "    z -- A number or numpy array\n",
    "    Return:\n",
    "    a -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    a = 1 / (1 + np.exp(-z)) # Sigmoid function\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_zeros(dim):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "    dim -- size of w \n",
    "    \n",
    "    Returns:\n",
    "    w -- a numpy vector of shape (dim, 1)\n",
    "    b -- a number\n",
    "    \"\"\"\n",
    "    \n",
    "    s = (dim, 1)\n",
    "    w = np.zeros(s)\n",
    "    b = 0.0\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3\n",
    "w, b = init_zeros(dim)\n",
    "print('w = {}'.format(w))\n",
    "print('b = {}'.format(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(X, Y, w, b):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    X -- data of size (64 * 64, number of examples)\n",
    "    Y -- true label vector of size (1, number of examples)\n",
    "    w -- weights, a numpy array of size (64 * 64, 1)\n",
    "    b -- bias, a scalar\n",
    "    \n",
    "    Returns:\n",
    "    grads -- containing gradients, dw and db\n",
    "    cost -- cost for the current pass\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Forward\n",
    "    A = sigmoid(w.T.dot(X) + b)\n",
    "    cost = (-1/m) * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
    "    \n",
    "    # Backward\n",
    "    dZ = A - Y\n",
    "    dw = (1/m) * np.dot(X, dZ.T)\n",
    "    db = (1/m) * np.sum(dZ)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    grads = {'dw': dw, 'db': db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,-3,0],[0.5,6,-5,0]])\n",
    "Y = np.array([[1,0,1,0]])\n",
    "w = np.array([[1],[2]])\n",
    "b = 0\n",
    "grads, cost = forward_backward(X, Y, w, b)\n",
    "\n",
    "print('dw = {}'.format(grads['dw']))\n",
    "print('db = {}'.format(grads['db']))\n",
    "print('cost = {}'.format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "&nbsp;|&nbsp;\n",
    "--|--\n",
    "**dw =**|[[1.22019716] <br> [2.73509556]]\n",
    "**db =**| 0.09519962669353813\n",
    "**cost =**| 6.9550195708335805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(X, Y, w, b, num_iters, alpha, verbose=False):\n",
    "    \"\"\"\n",
    "    Implement gradient descent\n",
    "    \n",
    "    Args:\n",
    "    X -- data of size (64 * 64, number of examples)\n",
    "    Y -- true label vector of size (1, number of examples)\n",
    "    w -- weights, a numpy array of size (64 * 64, 1)\n",
    "    b -- bias, a scalar\n",
    "    num_iters -- number of iterations\n",
    "    alpha -- learning rate\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    costs -- list of all the costs computed during the training, this will be used to plot the learning curve.\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    m = X.shape[1]\n",
    "    for i in range(num_iters):\n",
    "        # Compute gradient and cost by calling forward_backward function\n",
    "        grads, cost = forward_backward(X, Y, w, b)\n",
    "        \n",
    "        # Obtain dw and db\n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        # Update parameters\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "        \n",
    "        # Record and print cost every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if i % 100 == 0 and verbose:\n",
    "            print(\"Cost after iter {}: {}\".format(i, cost))\n",
    "        \n",
    "    params = {'w': w, 'b': b}\n",
    "    return params, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, costs = GD(X, Y, w, b, num_iters=1000, alpha=0.01)\n",
    "print('w = {}'.format(params['w']))\n",
    "print('b = {}'.format(params['b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output:\n",
    "&nbsp;|&nbsp;\n",
    "--|--\n",
    "**w =**|[[ 0.57327302] <br> [-0.8933432 ]]\n",
    "**b =**| 0.05089921193049401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Implement predict function\n",
    "    \n",
    "    Args:\n",
    "    X -- data of size (64 * 64, number of examples)\n",
    "    w -- weights, a numpy array of size (64 * 64, 1)\n",
    "    b -- bias, a scalar\n",
    "    \n",
    "    Returns:\n",
    "    Y_pred -- a numpy array of size (1, number of examples) containing all predictions (0/1) for all the examples in X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_pred = np.zeros((1, m))\n",
    "    A = sigmoid(w.T.dot(X) + b) # Compute the activation A\n",
    "    \n",
    "    # Convert probabilities to binary predictions\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] > 0.5: Y_pred[0, i] = 1\n",
    "        else: Y_pred[0, i] = 0\n",
    "    \n",
    "    assert(Y_pred.shape == (1, m))\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('predictions = {}'.format(predict(X, w, b)))\n",
    "print('predictions = {}'.format(predict(X, params['w'], params['b'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "&nbsp;|&nbsp;\n",
    "--|--\n",
    "**predictions** | [[1. 1. 0. 0.]]\n",
    "**predictions** | [[1. 0. 1. 1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iters=2000, alpha=0.005, verbose=False):\n",
    "    \"\"\"\n",
    "    Integrated model\n",
    "    \n",
    "    Args:\n",
    "    X_train -- training data of size (4096, 286)\n",
    "    Y_train -- training label of size (1, 286)\n",
    "    X_test -- test data of size (4096, 125)\n",
    "    Y_test -- test label of size (1, 125)\n",
    "    \n",
    "    Returns:\n",
    "    result -- a dict object that contains useful information\n",
    "    \"\"\"\n",
    "    \n",
    "    w, b = init_zeros(X_train.shape[0]) # Initialize parameters to zeros\n",
    "    \n",
    "    # Conduct gradient descent\n",
    "    params, costs = GD(X_train, Y_train, w, b, num_iters, alpha, verbose=False)\n",
    "    \n",
    "    # Retrieve parameters\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    \n",
    "    # Use the parameters to predict on train and test data\n",
    "    Y_pred_train = predict(X_train, w, b)\n",
    "    Y_pred_test = predict(X_test, w, b)\n",
    "    \n",
    "    # Compute the accuracies of predicting on train/test data\n",
    "    # Accuracy is the fraction of correct predictions over all examples\n",
    "    acc_train = np.sum(Y_train == Y_pred_train) / Y_train.shape[1]\n",
    "    acc_test = np.sum(Y_test == Y_pred_test) / Y_test.shape[1]\n",
    "    \n",
    "    # Print train/test accuracies\n",
    "    print('train accuracy: {} %'.format(100 * acc_train))\n",
    "    print('test accuracy: {} %'.format(100 * acc_test))\n",
    "    \n",
    "    result = { 'w': w, 'b': b, 'costs': costs, 'Y_pred_test': Y_pred_test }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT change the values of num_iters or alpha\n",
    "res = model(X_train, Y_train, X_test, Y_test, num_iters=1500, alpha=0.002, verbose=True)\n",
    "# Plot learning curve\n",
    "costs = np.squeeze(res['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title('Learning rate = 0.002')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "&nbsp;|&nbsp;\n",
    "--|--\n",
    "Cost after iter 0: |0.6931471805599454\n",
    "Cost after iter 100: |0.5946773825987639\n",
    "Cost after iter 200: |0.5256364501984687\n",
    "Cost after iter 300: |0.4747208768166399\n",
    "Cost after iter 400: |0.435436416758632\n",
    "Cost after iter 500: |0.40399872095331557\n",
    "Cost after iter 600: |0.37811027839268685\n",
    "Cost after iter 700: |0.35630887692114865\n",
    "Cost after iter 800: |0.3376209341419335\n",
    "Cost after iter 900: |0.32137148224069756\n",
    "Cost after iter 1000: |0.30707586651947666\n",
    "Cost after iter 1100: |0.29437547177794215\n",
    "Cost after iter 1200: |0.28299807348845724\n",
    "Cost after iter 1300: |0.27273248705908887\n",
    "Cost after iter 1400: |0.26341182071904296\n",
    "train accuracy: | 94.05594405594405 %\n",
    "test accuracy: | 88.0 %\n",
    "\n",
    "<br>\n",
    "<img src=\"lc.png\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that label y = 1 is positive, and y = 0 is negative\n",
    "def calc_metrics(Y_test, Y_pred_test):\n",
    "    \"\"\"\n",
    "    Calculate metrics (TP, FP, TN, FN, Accuracy, Precision, Recall, and F-1 score)\n",
    "    \n",
    "    Args:\n",
    "    Y_test -- test label\n",
    "    Y_pred_test -- predictions on test data\n",
    "    \n",
    "    Return:\n",
    "    metrics -- a dict object\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(Y_test.shape == Y_pred_test.shape)\n",
    "    \n",
    "    TP = np.sum(np.logical_and(Y_pred_test == 1, Y_test == 1))\n",
    "    TN = np.sum(np.logical_and(Y_pred_test == 0, Y_test == 0))\n",
    "    FP = np.sum(np.logical_and(Y_pred_test == 1, Y_test == 0))\n",
    "    FN = np.sum(np.logical_and(Y_pred_test == 0, Y_test == 1))\n",
    "            \n",
    "    Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    Precision = TP / (TP + FP)\n",
    "    Recall = TP / (TP + FN)\n",
    "    F1 = (2*(Precision * Recall)) / (Precision + Recall)\n",
    "    \n",
    "    metrics = {\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'TN': TN,\n",
    "        'FN': FN,\n",
    "        'Accuracy': Accuracy,\n",
    "        'Precision': Precision,\n",
    "        'Recall': Recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = calc_metrics(Y_test, res['Y_pred_test'])\n",
    "print('TP = {}, FP = {}, TN = {}, FN = {}, \\nAccuracy = {}, Precision = {}, Recall = {}, F1 = {}'.format(\n",
    "    m['TP'], m['FP'], m['TN'], m['FN'], m['Accuracy'], m['Precision'], m['Recall'], m['F1']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "&nbsp;|&nbsp;|&nbsp;|&nbsp;\n",
    "--|--|--|--\n",
    "TP = 59 | FP = 11 | TN = 51 | FN = 4\n",
    "Accuracy = 0.88 | Precision = 0.8428571428571429 | Recall = 0.9365079365079365 | F1 = 0.887218045112782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
